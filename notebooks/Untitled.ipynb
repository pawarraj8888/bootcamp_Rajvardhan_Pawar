{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794bb843-ca19-499d-a4e3-3b383ca4c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib, os\n",
    "from datetime import datetime\n",
    "ROOT = pathlib.Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.config import load_env, get\n",
    "load_env()\n",
    "\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts(): return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "def save_csv(df, path):\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\"Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd31bb9-187f-454b-ab0d-7ddf7b2b611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>date</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>243.873062</td>\n",
       "      <td>244.470001</td>\n",
       "      <td>245.179993</td>\n",
       "      <td>241.839996</td>\n",
       "      <td>244.149994</td>\n",
       "      <td>48822500</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>244.272079</td>\n",
       "      <td>244.869995</td>\n",
       "      <td>246.009995</td>\n",
       "      <td>243.160004</td>\n",
       "      <td>244.660004</td>\n",
       "      <td>32204200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>245.229752</td>\n",
       "      <td>245.830002</td>\n",
       "      <td>246.779999</td>\n",
       "      <td>244.289993</td>\n",
       "      <td>244.940002</td>\n",
       "      <td>32316900</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>244.950424</td>\n",
       "      <td>245.550003</td>\n",
       "      <td>248.690002</td>\n",
       "      <td>245.220001</td>\n",
       "      <td>245.949997</td>\n",
       "      <td>53197400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>246.496643</td>\n",
       "      <td>247.100006</td>\n",
       "      <td>248.860001</td>\n",
       "      <td>244.419998</td>\n",
       "      <td>244.929993</td>\n",
       "      <td>51326400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        date   adj_close       close        high         low        open  \\\n",
       "Ticker                   AAPL        AAPL        AAPL        AAPL        AAPL   \n",
       "0      2025-02-18  243.873062  244.470001  245.179993  241.839996  244.149994   \n",
       "1      2025-02-19  244.272079  244.869995  246.009995  243.160004  244.660004   \n",
       "2      2025-02-20  245.229752  245.830002  246.779999  244.289993  244.940002   \n",
       "3      2025-02-21  244.950424  245.550003  248.690002  245.220001  245.949997   \n",
       "4      2025-02-24  246.496643  247.100006  248.860001  244.419998  244.929993   \n",
       "\n",
       "Price     volume ticker  \n",
       "Ticker      AAPL         \n",
       "0       48822500   AAPL  \n",
       "1       32204200   AAPL  \n",
       "2       32316900   AAPL  \n",
       "3       53197400   AAPL  \n",
       "4       51326400   AAPL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, requests, yfinance as yf\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "AV_KEY = get(\"ALPHAVANTAGE_API_KEY\")\n",
    "\n",
    "def ingest_api_finance(ticker: str) -> pd.DataFrame:\n",
    "    if AV_KEY:\n",
    "        url = \"https://www.alphavantage.co/query\"\n",
    "        params = {\"function\":\"TIME_SERIES_DAILY_ADJUSTED\",\"symbol\":ticker,\"apikey\":AV_KEY,\"outputsize\":\"compact\"}\n",
    "        js = requests.get(url, params=params, timeout=30).json()\n",
    "        ts_key = \"Time Series (Daily)\"\n",
    "        assert ts_key in js, f\"Unexpected payload keys: {list(js)[:5]}\"\n",
    "        recs = []\n",
    "        for dt, row in js[ts_key].items():\n",
    "            recs.append({\n",
    "                \"date\": pd.to_datetime(dt),\n",
    "                \"open\": float(row[\"1. open\"]), \"high\": float(row[\"2. high\"]),\n",
    "                \"low\": float(row[\"3. low\"]), \"close\": float(row[\"4. close\"]),\n",
    "                \"adj_close\": float(row.get(\"5. adjusted close\", row[\"4. close\"])),\n",
    "                \"volume\": int(row[\"6. volume\"]), \"ticker\": ticker\n",
    "            })\n",
    "        df = pd.DataFrame(recs).sort_values(\"date\").reset_index(drop=True)\n",
    "    else:\n",
    "        df = yf.download(ticker, period=\"6mo\", interval=\"1d\", auto_adjust=False).reset_index()\n",
    "        df = df.rename(columns={\"Date\":\"date\",\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\n",
    "                                \"Close\":\"close\",\"Adj Close\":\"adj_close\",\"Volume\":\"volume\"})\n",
    "        df[\"ticker\"] = ticker\n",
    "    return df\n",
    "\n",
    "df_api = ingest_api_finance(TICKER)\n",
    "df_api.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d291893-af4c-4ed5-97f5-a3f25aedf8f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume', 'ticker']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/95/5w5lpz_d0fz83j8k9hzy9_zw0000gn/T/ipykernel_23560/1935725380.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m df_api[num_cols] = df_api[num_cols].apply(pd.to_numeric, errors=\u001b[33m\"coerce\"\u001b[39m)\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2) Drop rows that are invalid after coercion (safer than filling)\u001b[39;00m\n\u001b[32m      9\u001b[39m req = [\u001b[33m\"date\"\u001b[39m,\u001b[33m\"open\"\u001b[39m,\u001b[33m\"high\"\u001b[39m,\u001b[33m\"low\"\u001b[39m,\u001b[33m\"close\"\u001b[39m,\u001b[33m\"adj_close\"\u001b[39m,\u001b[33m\"volume\"\u001b[39m,\u001b[33m\"ticker\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_api = df_api.dropna(subset=req)\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 3) Enforce dtypes (volume as int)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m pd.api.types.is_integer_dtype(df_api[\u001b[33m\"volume\"\u001b[39m]):\n",
      "\u001b[32m/opt/anaconda3/envs/fe-course/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6673\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6674\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6675\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6676\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6677\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6678\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6679\u001b[39m \n\u001b[32m   6680\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume', 'ticker']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_cols = [\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"]\n",
    "\n",
    "# 1) Coerce numeric-like columns\n",
    "df_api[num_cols] = df_api[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 2) Drop rows that are invalid after coercion (safer than filling)\n",
    "req = [\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\",\"ticker\"]\n",
    "df_api = df_api.dropna(subset=req)\n",
    "\n",
    "# 3) Enforce dtypes (volume as int)\n",
    "if not pd.api.types.is_integer_dtype(df_api[\"volume\"]):\n",
    "    df_api[\"volume\"] = df_api[\"volume\"].astype(\"int64\")\n",
    "\n",
    "# 4) Re-run validations\n",
    "missing = [c for c in req if c not in df_api.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "assert pd.api.types.is_datetime64_any_dtype(df_api[\"date\"]), \"date must be datetime\"\n",
    "for c in [\"open\",\"high\",\"low\",\"close\",\"adj_close\"]:\n",
    "    assert pd.api.types.is_numeric_dtype(df_api[c]), f\"{c} must be numeric\"\n",
    "assert pd.api.types.is_integer_dtype(df_api[\"volume\"]), \"volume must be int\"\n",
    "assert df_api[\"ticker\"].nunique() == 1, \"expected a single ticker\"\n",
    "assert df_api[req].isna().sum().sum() == 0, \"no NAs allowed in required columns\"\n",
    "\n",
    "# 5) Save\n",
    "api_path = RAW_DIR / (f\"api_alphavantage_{TICKER}_{ts()}.csv\" if AV_KEY else f\"api_yahoo_{TICKER}_{ts()}.csv\")\n",
    "save_csv(df_api, api_path)\n",
    "print(\"Saved:\", api_path)\n",
    "print(df_api.dtypes)\n",
    "print(df_api[num_cols].head())\n",
    "print(df_api[num_cols].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f56c30-0de2-4001-a6ae-183e10bc37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml, requests\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "html = requests.get(URL, timeout=30).text\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find(\"table\", {\"id\":\"constituents\"}) or soup.find(\"table\", {\"class\":\"wikitable\"})\n",
    "rows = []\n",
    "for tr in table.select(\"tr\")[1:]:\n",
    "    tds = [td.get_text(strip=True) for td in tr.select(\"td\")]\n",
    "    if len(tds) >= 2:\n",
    "        rows.append({\"symbol\": tds[0], \"security\": tds[1]})\n",
    "df_spx = pd.DataFrame(rows)\n",
    "df_spx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17381f-f74c-4a1e-8be3-d13133920558",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not df_spx.empty\n",
    "for c in [\"symbol\",\"security\"]:\n",
    "    assert c in df_spx.columns and df_spx[c].dtype == \"object\"\n",
    "assert df_spx[[\"symbol\",\"security\"]].isna().sum().sum() == 0\n",
    "\n",
    "scrape_path = RAW_DIR / f\"scrape_wikipedia_sp500_{ts()}.csv\"\n",
    "save_csv(df_spx, scrape_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d3cb9-00d6-439c-a52b-2413232cf6e8",
   "metadata": {},
   "source": [
    "### Sources & Parameters\n",
    "- Finance API: Alpha Vantage (if key present) or yfinance for AAPL.\n",
    "- Scrape: Wikipedia S&P 500 constituents.\n",
    "\n",
    "**Validation**\n",
    "- API: required columns, dtypes, no NAs, single ticker.\n",
    "- Scrape: required text columns present, no NAs.\n",
    "\n",
    "**Assumptions/Risks**\n",
    "- Wiki table structure may change; API may throttle; adjusted-close semantics differ by source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2a3c9-0d06-4668-bed7-419ba4837f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fe-course)",
   "language": "python",
   "name": "fe-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
