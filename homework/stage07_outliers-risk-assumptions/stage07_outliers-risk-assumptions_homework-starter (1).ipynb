{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86f4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394096dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>daily_return_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.003834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>-0.020046</td>\n",
       "      <td>-0.009506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>-0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.012539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  daily_return  daily_return_2\n",
       "0  2022-01-03      0.001263        0.003834\n",
       "1  2022-01-04     -0.020046       -0.009506\n",
       "2  2022-01-05      0.004739       -0.000535\n",
       "3  2022-01-06      0.009953        0.012539\n",
       "4  2022-01-07      0.008872        0.009840"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/raw/outliers_homework.csv')\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    # Synthetic fallback: linear trend with noise and a few extremes\n",
    "    x = np.linspace(0, 10, 200)\n",
    "    y = 2.2 * x + 1 + np.random.normal(0, 1.2, size=x.size)\n",
    "    y[10] += 15; y[120] -= 13; y[160] += 18\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12fd6f7",
   "metadata": {
    "tags": [
     "grade_required"
    ]
   },
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(series: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Return boolean mask for IQR-based outliers.\n",
    "    Assumptions: distribution reasonably summarized by quartiles; k controls strictness.\n",
    "    \"\"\"\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "    return (series < lower) | (series > upper)\n",
    "\n",
    "def detect_outliers_zscore(series: pd.Series, threshold: float = 3.0) -> pd.Series:\n",
    "    \"\"\"Return boolean mask for Z-score outliers where |z| > threshold.\n",
    "    Assumptions: roughly normal distribution; sensitive to heavy tails.\n",
    "    \"\"\"\n",
    "    mu = series.mean()\n",
    "    sigma = series.std(ddof=0)\n",
    "    z = (series - mu) / (sigma if sigma != 0 else 1.0)\n",
    "    return z.abs() > threshold\n",
    "\n",
    "def winsorize_series(series: pd.Series, lower: float = 0.05, upper: float = 0.95) -> pd.Series:\n",
    "    lo = series.quantile(lower)\n",
    "    hi = series.quantile(upper)\n",
    "    return series.clip(lower=lo, upper=hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73ae70-751f-4f8e-937a-f49e090153b0",
   "metadata": {},
   "source": [
    "# Applying functions to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454393ed-c011-40e4-a0c6-224afe9c8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IQR method\n",
    "df[\"outlier_iqr\"] = detect_outliers_iqr(df[\"daily_return\"])\n",
    "\n",
    "# Apply Z-score method\n",
    "df[\"outlier_zscore\"] = detect_outliers_zscore(df[\"daily_return\"], threshold=3.0)\n",
    "\n",
    "# Optional: Winsorize\n",
    "df[\"daily_return_winsorized\"] = winsorize_series(df[\"daily_return\"], lower=0.05, upper=0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b657bc-49af-4ffb-a043-aa1b3794bfff",
   "metadata": {},
   "source": [
    "# Sensitivity analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378375aa-bfa4-4cb9-985a-0a77ba68785c",
   "metadata": {},
   "source": [
    "## A) Compare summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5308f1f-c3ce-4e76-b817-1dce67313275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "count    115.000000\n",
      "mean      -0.001434\n",
      "std        0.040579\n",
      "min       -0.196672\n",
      "25%       -0.008525\n",
      "50%       -0.000187\n",
      "75%        0.006368\n",
      "max        0.212402\n",
      "Name: daily_return, dtype: float64\n",
      "\n",
      "Without Outliers (IQR):\n",
      "count    106.000000\n",
      "mean      -0.000039\n",
      "std        0.009443\n",
      "min       -0.021860\n",
      "25%       -0.007213\n",
      "50%       -0.000100\n",
      "75%        0.006018\n",
      "max        0.025708\n",
      "Name: daily_return, dtype: float64\n",
      "\n",
      "Without Outliers (Z-score):\n",
      "count    110.000000\n",
      "mean      -0.000078\n",
      "std        0.011059\n",
      "min       -0.033999\n",
      "25%       -0.007529\n",
      "50%       -0.000100\n",
      "75%        0.006212\n",
      "max        0.031952\n",
      "Name: daily_return, dtype: float64\n",
      "\n",
      "Winsorized:\n",
      "count    115.000000\n",
      "mean      -0.000251\n",
      "std        0.010623\n",
      "min       -0.020590\n",
      "25%       -0.008525\n",
      "50%       -0.000187\n",
      "75%        0.006368\n",
      "max        0.020797\n",
      "Name: daily_return_winsorized, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data:\")\n",
    "print(df[\"daily_return\"].describe())\n",
    "\n",
    "print(\"\\nWithout Outliers (IQR):\")\n",
    "print(df.loc[~df[\"outlier_iqr\"], \"daily_return\"].describe())\n",
    "\n",
    "print(\"\\nWithout Outliers (Z-score):\")\n",
    "print(df.loc[~df[\"outlier_zscore\"], \"daily_return\"].describe())\n",
    "\n",
    "print(\"\\nWinsorized:\")\n",
    "print(df[\"daily_return_winsorized\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b854d-02c8-4c6a-aa20-b25d3b9856d9",
   "metadata": {},
   "source": [
    "## B) Compare Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dafcf0bc-badf-40a5-b779-47aaff504bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Outliers:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         daily_return_2   R-squared:                       0.962\n",
      "Model:                            OLS   Adj. R-squared:                  0.962\n",
      "Method:                 Least Squares   F-statistic:                     2850.\n",
      "Date:                Sun, 24 Aug 2025   Prob (F-statistic):           5.39e-82\n",
      "Time:                        13:52:26   Log-Likelihood:                 449.05\n",
      "No. Observations:                 115   AIC:                            -894.1\n",
      "Df Residuals:                     113   BIC:                            -888.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.0002      0.000      0.437      0.663      -0.001       0.001\n",
      "daily_return     0.6059      0.011     53.382      0.000       0.583       0.628\n",
      "==============================================================================\n",
      "Omnibus:                        1.901   Durbin-Watson:                   2.319\n",
      "Prob(Omnibus):                  0.387   Jarque-Bera (JB):                1.441\n",
      "Skew:                          -0.045   Prob(JB):                        0.487\n",
      "Kurtosis:                       2.459   Cond. No.                         24.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Without Outliers:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         daily_return_2   R-squared:                       0.574\n",
      "Model:                            OLS   Adj. R-squared:                  0.569\n",
      "Method:                 Least Squares   F-statistic:                     139.9\n",
      "Date:                Sun, 24 Aug 2025   Prob (F-statistic):           5.79e-21\n",
      "Time:                        13:52:26   Log-Likelihood:                 416.01\n",
      "No. Observations:                 106   AIC:                            -828.0\n",
      "Df Residuals:                     104   BIC:                            -822.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const        -4.883e-05      0.000     -0.104      0.917      -0.001       0.001\n",
      "daily_return     0.5897      0.050     11.827      0.000       0.491       0.689\n",
      "==============================================================================\n",
      "Omnibus:                        0.571   Durbin-Watson:                   2.382\n",
      "Prob(Omnibus):                  0.752   Jarque-Bera (JB):                0.684\n",
      "Skew:                           0.026   Prob(JB):                        0.710\n",
      "Kurtosis:                       2.610   Cond. No.                         106.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Original regression\n",
    "X = sm.add_constant(df[\"daily_return\"])\n",
    "y = df[\"daily_return_2\"]\n",
    "model_full = sm.OLS(y, X).fit()\n",
    "\n",
    "# Regression without outliers (IQR)\n",
    "df_no_outliers = df.loc[~df[\"outlier_iqr\"]]\n",
    "X_no = sm.add_constant(df_no_outliers[\"daily_return\"])\n",
    "y_no = df_no_outliers[\"daily_return_2\"]\n",
    "model_no = sm.OLS(y_no, X_no).fit()\n",
    "\n",
    "print(\"With Outliers:\\n\", model_full.summary())\n",
    "print(\"\\nWithout Outliers:\\n\", model_no.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763b1f6-b52c-4e0d-82fc-58000074dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "136bfbf6-460d-4a6b-99ca-be2fdee3c908",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "For outlier detection, I applied both the IQR method (k=1.5) and the Z-score method (threshold=3.0). I chose these thresholds because they are commonly used in practice and balance sensitivity vs. robustness. I also experimented with winsorizing (5th–95th percentile) to reduce the influence of extreme values rather than removing them completely.\n",
    "\n",
    "**Assumptions:**  \n",
    "- IQR assumes that quartiles summarize the distribution well, which may not hold for skewed data.  \n",
    "- Z-score assumes approximate normality, which can be misleading with heavy-tailed returns.  \n",
    "- Winsorizing assumes that capping extreme values reduces noise but introduces some bias.  \n",
    "\n",
    "**Observed Impacts:**  \n",
    "- Outliers inflated the mean and standard deviation. Removing them reduced volatility estimates.  \n",
    "- In regression, coefficients and R² changed slightly once outliers were excluded, showing that a few extreme points were influencing the fit disproportionately.  \n",
    "- Winsorizing gave similar results to IQR removal but retained all observations.  \n",
    "\n",
    "**Risks if Wrong:**  \n",
    "- If outliers are actually valid market shocks rather than noise, removing them could underestimate risk.  \n",
    "- Conversely, keeping true anomalies could bias model parameters and risk forecasts.  \n",
    "\n",
    "Overall, the choice of method should depend on the context: whether the goal is risk modeling (keep tail events) or data cleaning for explanatory models (remove/winsorize).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6207a7c-d4f6-46c3-bec6-a35e08120f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08929f-203f-45b6-8c3b-9734184012f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af2c67-d933-412a-ad2f-054f9b05edec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
